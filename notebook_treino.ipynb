{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731969e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "StatsForecast Version: 2.0.1\n",
      "Usando arquivo de dados: C:/Users/ReDragon/Desktop/TECH_CHALLENTE_F4/dados/preco_petroleo.csv\n",
      "Arquivos de modelo serão salvos em: c:\\Users\\ReDragon\\Desktop\\TECH_CHALLENTE_F4\n",
      "Classes de Pipeline definidas.\n",
      "Função calcula_erro_notebook definida.\n",
      "Dados filtrados para os últimos 10 anos (a partir de 2014-11-04). Formato: (2961, 2)\n",
      "\n",
      "--- Treinando Modelo AutoARIMAX (StatsForecast) para salvar (10 anos com features) ---\n",
      ">>> Scaler para features exógenas do ARIMAX salvo como './scaler_exog_arima.pkl' <<<\n",
      "Ajustando AutoARIMAX com season_length=30. As features exógenas estão no DataFrame de entrada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ReDragon\\AppData\\Local\\Temp\\ipykernel_1820\\2423950355.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy[self.value_col].ffill(inplace=True); df_copy[self.value_col].bfill(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoARIMAX (10 anos com features) ajustado.\n",
      "Saving StatsForecast object of size 434.40KB.\n",
      "StatsForecast object saved\n",
      ">>> Modelo AutoARIMAX (StatsForecast, 10 anos com features) salvo como './sarima_model_sf.pkl' <<<\n",
      "\n",
      "--- Gerando Features ARIMAX para LSTM Híbrido (baseado no modelo de 10 anos) ---\n",
      "Features ARIMAX (10 anos) geradas e revertidas para escala original. Formato: (3654, 2)\n",
      "\n",
      "--- Preparando Dados Combinados e Features Sazonais para LSTM Híbrido (10 anos) ---\n",
      "Dados combinados com features sazonais para LSTM. Formato: (3654, 6)\n",
      "\n",
      "--- Treinamento do Modelo LSTM Híbrido (10 anos com Features Sazonais) ---\n",
      ">>> Scaler LSTM (Híbrido com Features, 10 anos) salvo como './scaler.pkl' <<<\n",
      "LSTM usará seq_length=90 e num_features=6\n",
      "Formato de X_train_lstm_tuned (multivariado): (2852, 90, 6)\n",
      "\n",
      "Iniciando treinamento do modelo LSTM híbrido com features sazonais (10 anos)...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ReDragon\\AppData\\Local\\Temp\\ipykernel_1820\\2423950355.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy[self.value_col].ffill(inplace=True); df_copy[self.value_col].bfill(inplace=True)\n",
      "c:\\Users\\ReDragon\\Desktop\\TECH_CHALLENTE_F4\\venv_py310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - loss: 0.0614 - val_loss: 0.0040\n",
      "Epoch 2/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 3/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 5/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 6/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 8/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 9/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 11/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 12/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 13/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0014 - val_loss: 9.4537e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 17/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0013 - val_loss: 7.5575e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 19/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 22/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0010 - val_loss: 5.7116e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 26/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 8.9456e-04 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 9.5986e-04 - val_loss: 0.0030\n",
      "Epoch 29/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 9.0883e-04 - val_loss: 6.5875e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 9.2335e-04 - val_loss: 6.2191e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 9.9583e-04 - val_loss: 8.1602e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 8.5313e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 8.0486e-04 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 8.6477e-04 - val_loss: 8.8681e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 8.3740e-04 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 9.0535e-04 - val_loss: 0.0013\n",
      "Epoch 38/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 8.0365e-04 - val_loss: 7.2154e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.6160e-04 - val_loss: 7.9702e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.4959e-04 - val_loss: 5.4950e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 8.3128e-04 - val_loss: 8.7924e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 6.7532e-04 - val_loss: 9.6996e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 7.0631e-04 - val_loss: 0.0011\n",
      "Epoch 44/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 8.3176e-04 - val_loss: 5.4093e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 7.4101e-04 - val_loss: 4.7369e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 7.4295e-04 - val_loss: 8.3348e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.5236e-04 - val_loss: 6.2358e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.7858e-04 - val_loss: 4.7144e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.3376e-04 - val_loss: 4.5589e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.1628e-04 - val_loss: 5.5466e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.2853e-04 - val_loss: 4.8115e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.3005e-04 - val_loss: 4.9406e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 7.3284e-04 - val_loss: 8.2856e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.3140e-04 - val_loss: 5.2702e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 6.5783e-04 - val_loss: 5.3790e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.1106e-04 - val_loss: 4.5665e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.0754e-04 - val_loss: 4.3257e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 5.9504e-04 - val_loss: 4.6497e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 6.0382e-04 - val_loss: 4.9292e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 6.6131e-04 - val_loss: 5.0872e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 7.2798e-04 - val_loss: 5.7082e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 6.6773e-04 - val_loss: 5.1604e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 7.0135e-04 - val_loss: 4.6055e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 6.4098e-04 - val_loss: 4.3564e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 6.4850e-04 - val_loss: 4.4682e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.0827e-04 - val_loss: 4.8797e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.3210e-04 - val_loss: 4.6462e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 5.6193e-04 - val_loss: 4.2541e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 5.3595e-04 - val_loss: 4.0103e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.2411e-04 - val_loss: 4.5577e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 5.5056e-04 - val_loss: 4.1986e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.3071e-04 - val_loss: 3.9571e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 5.3888e-04 - val_loss: 3.8304e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 5.1616e-04 - val_loss: 3.9890e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 6.2156e-04 - val_loss: 8.4270e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 6.1281e-04 - val_loss: 3.6741e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 5.6284e-04 - val_loss: 4.5411e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 5.9491e-04 - val_loss: 4.4155e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 5.8250e-04 - val_loss: 3.6294e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 4.7863e-04 - val_loss: 4.9929e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 5.2806e-04 - val_loss: 3.7619e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 5.6133e-04 - val_loss: 3.6848e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 5.2172e-04 - val_loss: 3.4571e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 4.6664e-04 - val_loss: 3.5851e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 5.2930e-04 - val_loss: 4.5752e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.8070e-04 - val_loss: 3.6182e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 4.7920e-04 - val_loss: 3.6303e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.7411e-04 - val_loss: 4.6442e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.9370e-04 - val_loss: 3.3193e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 5.1560e-04 - val_loss: 3.3411e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 4.9744e-04 - val_loss: 3.5305e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.8963e-04 - val_loss: 3.2915e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 5.0690e-04 - val_loss: 3.2363e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.7873e-04 - val_loss: 3.5494e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 5.3141e-04 - val_loss: 3.4893e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 4.7504e-04 - val_loss: 3.5185e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.5395e-04 - val_loss: 3.3633e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.6106e-04 - val_loss: 4.0121e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 5.0665e-04 - val_loss: 4.0509e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.1798e-04 - val_loss: 3.5391e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 4.5673e-04 - val_loss: 3.4264e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.5087e-04 - val_loss: 4.1236e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 4.7330e-04 - val_loss: 3.3151e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 4.3378e-04 - val_loss: 4.8854e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 5.3902e-04 - val_loss: 3.6228e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 4.6073e-04 - val_loss: 3.1446e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.3937e-04 - val_loss: 3.4694e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 4.2827e-04 - val_loss: 3.1590e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 4.1993e-04 - val_loss: 5.1690e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 5.3517e-04 - val_loss: 3.1951e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 4.0978e-04 - val_loss: 3.9307e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.2414e-04 - val_loss: 3.4689e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 4.4200e-04 - val_loss: 4.0897e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 4.9540e-04 - val_loss: 3.1472e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.9433e-04 - val_loss: 3.0757e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 4.6971e-04 - val_loss: 3.4138e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.3617e-04 - val_loss: 2.9990e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.0524e-04 - val_loss: 3.4174e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 3.8911e-04 - val_loss: 3.3313e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 4.1054e-04 - val_loss: 3.0396e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 4.1429e-04 - val_loss: 3.8587e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 4.2688e-04 - val_loss: 2.9904e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 3.7997e-04 - val_loss: 2.9627e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 3.8409e-04 - val_loss: 3.1473e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 3.8730e-04 - val_loss: 4.2079e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 4.3423e-04 - val_loss: 3.4032e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 4.9137e-04 - val_loss: 2.9944e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 4.5508e-04 - val_loss: 3.1824e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 4.1473e-04 - val_loss: 3.5732e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 4.8483e-04 - val_loss: 3.7869e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 4.3388e-04 - val_loss: 3.0142e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.1286e-04 - val_loss: 4.1566e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.2408e-04 - val_loss: 2.9026e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 4.0882e-04 - val_loss: 3.0147e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 4.0636e-04 - val_loss: 3.8074e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 4.3265e-04 - val_loss: 2.8417e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 3.9046e-04 - val_loss: 3.1665e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 4.3837e-04 - val_loss: 2.8340e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 4.1675e-04 - val_loss: 2.9416e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 4.1510e-04 - val_loss: 4.2284e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 4.6198e-04 - val_loss: 2.9205e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 4.2396e-04 - val_loss: 3.0877e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 4.0914e-04 - val_loss: 4.5354e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 4.5499e-04 - val_loss: 2.7169e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 4.1188e-04 - val_loss: 2.7193e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 3.9051e-04 - val_loss: 2.6588e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 3.6794e-04 - val_loss: 2.9705e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 3.5164e-04 - val_loss: 2.9030e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 4.4085e-04 - val_loss: 2.8217e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 3.9137e-04 - val_loss: 2.6212e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 4.2602e-04 - val_loss: 2.8125e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 5.3805e-04 - val_loss: 3.3413e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 3.8802e-04 - val_loss: 2.9366e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 3.9895e-04 - val_loss: 3.3773e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 4.2717e-04 - val_loss: 5.4422e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 5.0306e-04 - val_loss: 2.7071e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 3.8905e-04 - val_loss: 3.0730e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 3.8837e-04 - val_loss: 4.2296e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 3.5367e-04 - val_loss: 2.6988e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 3.8691e-04 - val_loss: 3.4629e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 3.7009e-04 - val_loss: 2.7086e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 3.9681e-04 - val_loss: 2.5145e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 4.0677e-04 - val_loss: 2.4235e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 3.7038e-04 - val_loss: 2.4495e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 3.8134e-04 - val_loss: 2.5261e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 3.7884e-04 - val_loss: 2.7136e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 4.0670e-04 - val_loss: 2.6730e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 3.7144e-04 - val_loss: 3.0892e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.6403e-04 - val_loss: 2.7630e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 3.7747e-04 - val_loss: 2.6716e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.7030e-04 - val_loss: 3.9551e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 3.6976e-04 - val_loss: 2.7226e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 3.8287e-04 - val_loss: 2.7821e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 3.5819e-04 - val_loss: 2.8612e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - loss: 3.6576e-04 - val_loss: 2.3822e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 3.7550e-04 - val_loss: 2.4293e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 3.5739e-04 - val_loss: 2.3377e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 3.6204e-04 - val_loss: 2.6792e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.9010e-04 - val_loss: 4.0262e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 3.8799e-04 - val_loss: 3.1214e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.9117e-04 - val_loss: 3.2857e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 3.4996e-04 - val_loss: 2.2969e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.2372e-04 - val_loss: 2.6068e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.7981e-04 - val_loss: 2.4590e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 4.0431e-04 - val_loss: 2.8403e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.5384e-04 - val_loss: 2.2799e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.2924e-04 - val_loss: 2.2436e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 4.0265e-04 - val_loss: 2.2676e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.6880e-04 - val_loss: 2.5762e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.8214e-04 - val_loss: 2.3930e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.6641e-04 - val_loss: 2.2508e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.7765e-04 - val_loss: 2.4252e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.2996e-04 - val_loss: 2.2576e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.4414e-04 - val_loss: 3.1703e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 3.6204e-04 - val_loss: 2.3537e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.5754e-04 - val_loss: 2.3128e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.3736e-04 - val_loss: 2.6894e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.3459e-04 - val_loss: 2.3604e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 3.5254e-04 - val_loss: 2.9413e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 3.3685e-04 - val_loss: 2.1266e-04\n",
      "Restoring model weights from the end of the best epoch: 200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento LSTM (10 anos com features) concluído.\n",
      ">>> Modelo LSTM híbrido (10 anos com features) salvo como './lstm_model.h5' <<<\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\n",
      "Métricas para LSTM Híbrido (10 anos com Features) no conjunto de validação:\n",
      "{'modelo': 'LSTM_Hibrido_ feats_10Anos_Val', 'mae': 1.343, 'rmse': np.float64(1.809), 'smape %': np.float64(1.65)}\n",
      ">>> Métricas de erro salvas como './df_erros.csv' <<<\n",
      "\n",
      "DataFrame de Erros (do Notebook):\n",
      "                            modelo    mae   rmse  smape %\n",
      "0  LSTM_Hibrido_ feats_10Anos_Val  1.343  1.809     1.65\n",
      "\n",
      "--- Processo de Geração de Artefatos (10 anos, ARIMAX e LSTM com features) Concluído ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 1: Imports e Configurações Iniciais\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Imports para Modelagem\n",
    "import statsforecast # Para verificar a versão\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.tsa.stattools import adfuller \n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf \n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"StatsForecast Version: {statsforecast.__version__}\")\n",
    "\n",
    "# --- Configuração de Caminhos ---\n",
    "output_directory = \"./\" \n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "file_path_data_notebook = 'dados/preco_petroleo.csv' \n",
    "print(f\"Usando arquivo de dados: {file_path_data_notebook}\")\n",
    "print(f\"Arquivos de modelo serão salvos em: {os.path.abspath(output_directory)}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 2: Definição das Classes do Pipeline e Função de Erro\n",
    "# ==============================================================================\n",
    "class PrepareData(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_col='Data', value_col='Value'):\n",
    "        self.date_col = date_col\n",
    "        self.value_col = value_col\n",
    "    def fit(self, df, y=None): return self\n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        if 'Date' in df_copy.columns and self.date_col == 'Data': df_copy.rename(columns={'Date': 'Data'}, inplace=True)\n",
    "        if 'Preço - petróleo bruto - Brent (FOB)' in df_copy.columns and self.value_col == 'Value': df_copy.rename(columns={'Preço - petróleo bruto - Brent (FOB)': 'Value'}, inplace=True)\n",
    "        if self.date_col not in df_copy.columns: raise ValueError(f\"Coluna de data '{self.date_col}' não encontrada.\")\n",
    "        if self.value_col not in df_copy.columns: raise ValueError(f\"Coluna de valor '{self.value_col}' não encontrada.\")\n",
    "        df_copy[self.date_col] = pd.to_datetime(df_copy[self.date_col])\n",
    "        df_copy.set_index(self.date_col, inplace=True); df_copy[self.value_col] = df_copy[self.value_col].astype(float)\n",
    "        df_copy.dropna(subset=[self.value_col], inplace=True); df_copy.sort_index(inplace=True, ascending=True)\n",
    "        return df_copy\n",
    "\n",
    "class FillNANValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, value_col='Value', new_value_col='y', new_date_col='ds'):\n",
    "        self.value_col, self.new_value_col, self.new_date_col = value_col, new_value_col, new_date_col\n",
    "    def fit(self, df, y=None): return self\n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        if not isinstance(df_copy.index, pd.DatetimeIndex): raise ValueError(\"DatetimeIndex esperado.\")\n",
    "        start_date, end_date = df_copy.index.min(), df_copy.index.max()\n",
    "        if pd.isna(start_date) or pd.isna(end_date) or df_copy.empty: return pd.DataFrame(columns=[self.new_date_col, self.new_value_col])\n",
    "        df_copy = df_copy.reindex(pd.date_range(start=start_date, end=end_date, freq='D'))\n",
    "        df_copy[self.value_col].ffill(inplace=True); df_copy[self.value_col].bfill(inplace=True)\n",
    "        df_copy.dropna(subset=[self.value_col], inplace=True)\n",
    "        if df_copy.empty: return pd.DataFrame(columns=[self.new_date_col, self.new_value_col])\n",
    "        df_copy.reset_index(inplace=True)\n",
    "        df_copy.rename(columns={'index': self.new_date_col, self.value_col: self.new_value_col}, inplace=True)\n",
    "        return df_copy[[self.new_date_col, self.new_value_col]]\n",
    "\n",
    "class SomthDataIntervalValues(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, value_col='y'): self.value_col = value_col\n",
    "    def fit(self, df, y=None): return self\n",
    "    def transform(self, df): \n",
    "        df_indexed = df.set_index('ds').copy()\n",
    "        series_to_log = df_indexed[self.value_col].apply(lambda x: x if x > 0 else 1e-5)\n",
    "        df_log = np.log(series_to_log)\n",
    "        ma_log = df_log.rolling(window=7, min_periods=1).mean() \n",
    "        df_diff = (df_log - ma_log)\n",
    "        df_transformed = pd.DataFrame(index=df_diff.index)\n",
    "        df_transformed['y_diff_log'] = df_diff; df_transformed['y_ma_log'] = ma_log\n",
    "        df_transformed.dropna(subset=['y_diff_log'], inplace=True); df_transformed.reset_index(inplace=True)\n",
    "        return df_transformed\n",
    "print(\"Classes de Pipeline definidas.\")\n",
    "\n",
    "calculos_erro_list_notebook = [] \n",
    "def calcula_erro_notebook(predicao, real, modelo_nome):\n",
    "    global calculos_erro_list_notebook\n",
    "    def symetric_mean_absolute_percentage_error(actual, predicted) -> float:\n",
    "        actual, predicted = np.array(actual).flatten(), np.array(predicted).flatten()\n",
    "        mask = ~ (np.isnan(actual) | np.isinf(actual) | np.isnan(predicted) | np.isinf(predicted))\n",
    "        actual, predicted = actual[mask], predicted[mask]\n",
    "        if len(actual) == 0: return np.nan\n",
    "        denominator = (np.abs(predicted) + np.abs(actual)) / 2.0; diff = np.abs(predicted - actual)\n",
    "        smape_values = np.where(denominator == 0, 0.0, diff / denominator)\n",
    "        return round(np.mean(smape_values) * 100, 2)\n",
    "    real_flat = np.array(real).flatten(); predicao_flat = np.array(predicao).flatten()\n",
    "    min_len = min(len(real_flat), len(predicao_flat))\n",
    "    if min_len == 0: retorno = {'modelo': modelo_nome, 'mae': np.nan, 'rmse': np.nan, 'smape %': np.nan}\n",
    "    else:\n",
    "        real_flat, predicao_flat = real_flat[:min_len], predicao_flat[:min_len]\n",
    "        mae = mean_absolute_error(real_flat, predicao_flat); rmse = np.sqrt(mean_squared_error(real_flat, predicao_flat))\n",
    "        smape = symetric_mean_absolute_percentage_error(real_flat, predicao_flat)\n",
    "        retorno = {'modelo': modelo_nome, 'mae': round(mae,3), 'rmse': round(rmse,3), 'smape %': smape}\n",
    "    calculos_erro_list_notebook.append(retorno)\n",
    "    return retorno\n",
    "print(\"Função calcula_erro_notebook definida.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 3: Carregar Dados e Filtrar para Últimos 10 Anos\n",
    "# ==============================================================================\n",
    "try:\n",
    "    df_brent_total_nb = pd.read_csv(file_path_data_notebook)\n",
    "    if 'Date' in df_brent_total_nb.columns and 'Value' in df_brent_total_nb.columns:\n",
    "        df_brent_total_nb.rename(columns={'Date': 'Data', 'Value': 'Value'}, inplace=True)\n",
    "    elif not ('Data' in df_brent_total_nb.columns and 'Value' in df_brent_total_nb.columns):\n",
    "        if len(df_brent_total_nb.columns) >= 2:\n",
    "             df_brent_total_nb.rename(columns={df_brent_total_nb.columns[0]: 'Data', df_brent_total_nb.columns[1]: 'Value'}, inplace=True)\n",
    "        else: raise ValueError(\"CSV não tem colunas 'Data' e 'Value'.\")\n",
    "    df_brent_total_nb['Data'] = pd.to_datetime(df_brent_total_nb['Data'])\n",
    "    df_brent_total_nb.sort_values('Data', inplace=True, ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(f\"Erro Crítico ao carregar dados originais: {e}\")\n",
    "    raise\n",
    "\n",
    "data_final_historico_nb = df_brent_total_nb['Data'].max()\n",
    "data_inicio_10_anos_nb = data_final_historico_nb - pd.DateOffset(years=10)\n",
    "df_brent_10anos_nb = df_brent_total_nb[df_brent_total_nb['Data'] >= data_inicio_10_anos_nb].copy()\n",
    "print(f\"Dados filtrados para os últimos 10 anos (a partir de {data_inicio_10_anos_nb.strftime('%Y-%m-%d')}). Formato: {df_brent_10anos_nb.shape}\")\n",
    "if df_brent_10anos_nb.empty: raise ValueError(\"DataFrame vazio após filtrar pelos últimos 10 anos.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 4: Treinamento do Modelo ARIMAX (StatsForecast com Features Exógenas) - CORRIGIDO (v3)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Treinando Modelo AutoARIMAX (StatsForecast) para salvar (10 anos com features) ---\")\n",
    "pipeline_arima_transform_nb = Pipeline([\n",
    "    ('data_prepator_arima', PrepareData(date_col='Data', value_col='Value')),\n",
    "    ('filler_nan_values_arima', FillNANValues(value_col='Value', new_value_col='y', new_date_col='ds')),\n",
    "    ('smoother_data_interval_arima', SomthDataIntervalValues(value_col='y'))\n",
    "])\n",
    "df_transformed_10a_for_arimax = pipeline_arima_transform_nb.fit_transform(df_brent_10anos_nb.copy())\n",
    "\n",
    "# DataFrame que será passado para StatsForecast.fit()\n",
    "# Deve conter 'unique_id', 'ds', 'y' (série alvo transformada) E as colunas de features exógenas escalonadas\n",
    "df_fit_arimax_with_exog = df_transformed_10a_for_arimax[['ds', 'y_diff_log']].copy()\n",
    "df_fit_arimax_with_exog.rename(columns={'y_diff_log': 'y'}, inplace=True)\n",
    "df_fit_arimax_with_exog['unique_id'] = 'Brent'\n",
    "df_fit_arimax_with_exog['ds'] = pd.to_datetime(df_fit_arimax_with_exog['ds'])\n",
    "\n",
    "if df_fit_arimax_with_exog.empty:\n",
    "    raise ValueError(\"DataFrame alvo para ARIMAX está vazio após transformações.\")\n",
    "\n",
    "# Criar features sazonais EXÓGENAS\n",
    "df_exog_features_temp = df_fit_arimax_with_exog[['ds']].copy() \n",
    "df_exog_features_temp['dia_da_semana'] = df_exog_features_temp['ds'].dt.dayofweek\n",
    "df_exog_features_temp['mes_sin'] = np.sin(2 * np.pi * df_exog_features_temp['ds'].dt.month / 12)\n",
    "df_exog_features_temp['mes_cos'] = np.cos(2 * np.pi * df_exog_features_temp['ds'].dt.month / 12)\n",
    "df_exog_features_temp['dia_do_ano_sin'] = np.sin(2 * np.pi * df_exog_features_temp['ds'].dt.dayofyear / 365.25)\n",
    "df_exog_features_temp['dia_do_ano_cos'] = np.cos(2 * np.pi * df_exog_features_temp['ds'].dt.dayofyear / 365.25)\n",
    "X_exog_arimax_unscaled_cols = ['dia_da_semana', 'mes_sin', 'mes_cos', 'dia_do_ano_sin', 'dia_do_ano_cos']\n",
    "X_exog_arimax_unscaled_values = df_exog_features_temp[X_exog_arimax_unscaled_cols]\n",
    "\n",
    "# Escalar features exógenas\n",
    "scaler_exog_arimax_notebook = MinMaxScaler(feature_range=(0,1))\n",
    "X_exog_arimax_scaled_values = scaler_exog_arimax_notebook.fit_transform(X_exog_arimax_unscaled_values)\n",
    "\n",
    "# Adicionar features exógenas escalonadas ao df_fit_arimax_with_exog\n",
    "# Os NOMES DAS COLUNAS DEVEM SER OS MESMOS que X_exog_arimax_unscaled_cols\n",
    "for i, col_name in enumerate(X_exog_arimax_unscaled_cols):\n",
    "    df_fit_arimax_with_exog[col_name] = X_exog_arimax_scaled_values[:, i]\n",
    "\n",
    "# Salvar o scaler das features exógenas do ARIMAX\n",
    "scaler_exog_arimax_path = os.path.join(output_directory, 'scaler_exog_arima.pkl')\n",
    "joblib.dump(scaler_exog_arimax_notebook, scaler_exog_arimax_path)\n",
    "print(f\">>> Scaler para features exógenas do ARIMAX salvo como '{scaler_exog_arimax_path}' <<<\")\n",
    "\n",
    "# Treinar AutoARIMA com features exógenas\n",
    "ARIMAX_SEASON_LENGTH = 30 \n",
    "# === CORREÇÃO FINAL PARA STATSFORECAST >= 2.0.0 ===\n",
    "# O AutoARIMA NÃO recebe 'exogenous' no construtor. Ele detecta automaticamente\n",
    "# colunas extras no DataFrame passado ao fit do StatsForecast.\n",
    "model_sf_arimax_to_save = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=ARIMAX_SEASON_LENGTH)], # SEM 'exogenous' aqui\n",
    "    freq='D',\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"Ajustando AutoARIMAX com season_length={ARIMAX_SEASON_LENGTH}. As features exógenas estão no DataFrame de entrada.\")\n",
    "# O método fit da StatsForecast recebe o DataFrame que já contém 'y' e as colunas exógenas.\n",
    "# O argumento X_df NÃO é usado no StatsForecast.fit()\n",
    "model_sf_arimax_to_save.fit(df_fit_arimax_with_exog) \n",
    "# ============================================================\n",
    "print(\"AutoARIMAX (10 anos com features) ajustado.\")\n",
    "\n",
    "model_sf_arimax_path_to_save = os.path.join(output_directory, 'sarima_model_sf.pkl')\n",
    "model_sf_arimax_to_save.save(model_sf_arimax_path_to_save)\n",
    "print(f\">>> Modelo AutoARIMAX (StatsForecast, 10 anos com features) salvo como '{model_sf_arimax_path_to_save}' <<<\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 5: Geração de Features ARIMAX para o LSTM Híbrido - CORRIGIDA\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Gerando Features ARIMAX para LSTM Híbrido (baseado no modelo de 10 anos) ---\")\n",
    "h_for_arimax_features_insample = len(df_fit_arimax_with_exog) \n",
    "\n",
    "# Para prever com o modelo ARIMAX treinado, precisamos fornecer as features exógenas\n",
    "# para o período da previsão. Neste caso, são as features históricas.\n",
    "# O X_df para o predict do StatsForecast deve conter 'unique_id', 'ds' e as colunas exógenas.\n",
    "X_df_for_predict_sf = df_fit_arimax_with_exog[['unique_id', 'ds'] + X_exog_arimax_unscaled_cols].copy()\n",
    "\n",
    "predicted_arimax_transformed_features = model_sf_arimax_to_save.predict(\n",
    "    h=h_for_arimax_features_insample, \n",
    "    X_df=X_df_for_predict_sf # Passa o DataFrame com as features exógenas históricas para o predict\n",
    ")\n",
    "\n",
    "# Reconstruir estas features ARIMAX para a escala original\n",
    "ma_log_series_aligned = df_transformed_10a_for_arimax.set_index('ds').loc[df_fit_arimax_with_exog['ds']]['y_ma_log']\n",
    "ma_log_relevant_arimax = ma_log_series_aligned.values\n",
    "\n",
    "len_preds_arimax = 30\n",
    "pred_col_name_arimax = 'AutoARIMA' \n",
    "if pred_col_name_arimax in predicted_arimax_transformed_features.columns:\n",
    "    len_preds_arimax = len(predicted_arimax_transformed_features[pred_col_name_arimax])\n",
    "    arimax_preds_values = predicted_arimax_transformed_features[pred_col_name_arimax].values\n",
    "elif not predicted_arimax_transformed_features.empty:\n",
    "    potential_pred_cols = [col for col in predicted_arimax_transformed_features.columns if col not in ['ds', 'unique_id']]\n",
    "    if potential_pred_cols:\n",
    "        pred_col_name_arimax = potential_pred_cols[0]\n",
    "        arimax_preds_values = predicted_arimax_transformed_features[pred_col_name_arimax].values\n",
    "        len_preds_arimax = len(arimax_preds_values)\n",
    "        print(f\"AVISO: Coluna 'AutoARIMA' não encontrada na previsão ARIMAX. Usando '{pred_col_name_arimax}'.\")\n",
    "    else: raise ValueError(\"Nenhuma coluna de previsão encontrada na saída do AutoARIMAX.\")\n",
    "else: raise ValueError(\"Previsão do AutoARIMAX resultou em DataFrame vazio.\")\n",
    "\n",
    "if len(ma_log_relevant_arimax) > len_preds_arimax:\n",
    "    ma_log_relevant_arimax = ma_log_relevant_arimax[-len_preds_arimax:]\n",
    "elif len(ma_log_relevant_arimax) < len_preds_arimax:\n",
    "    ma_log_relevant_arimax = np.pad(ma_log_relevant_arimax, \n",
    "                                   (0, len_preds_arimax - len(ma_log_relevant_arimax)),\n",
    "                                   'edge')\n",
    "features_arimax_orig_scale_10a = np.exp(\n",
    "    arimax_preds_values + ma_log_relevant_arimax\n",
    ")\n",
    "df_features_arimax_10a = pd.DataFrame({\n",
    "    'ds': predicted_arimax_transformed_features['ds'], \n",
    "    'y_arimax_feature': features_arimax_orig_scale_10a\n",
    "})\n",
    "print(f\"Features ARIMAX (10 anos) geradas e revertidas para escala original. Formato: {df_features_arimax_10a.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 6: Preparação dos Dados Combinados e Engenharia de Features Sazonais para LSTM\n",
    "# (Esta célula e as seguintes para LSTM permanecem as mesmas da resposta anterior)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preparando Dados Combinados e Features Sazonais para LSTM Híbrido (10 anos) ---\")\n",
    "pipeline_normalize_data_nb_10a = Pipeline([\n",
    "    ('data_prepator', PrepareData(date_col='Data', value_col='Value')),\n",
    "    ('filler_nan_values', FillNANValues(value_col='Value', new_value_col='y', new_date_col='ds'))])\n",
    "df_normalized_hist_10a_for_lstm = pipeline_normalize_data_nb_10a.fit_transform(df_brent_10anos_nb.copy())\n",
    "df_normalized_hist_10a_for_lstm['ds'] = pd.to_datetime(df_normalized_hist_10a_for_lstm['ds'])\n",
    "\n",
    "df_combinado_para_lstm_pre_feat = df_normalized_hist_10a_for_lstm.merge(\n",
    "    df_features_arimax_10a.rename(columns={'y_arimax_feature': 'y_arima_feature'}), on='ds', how='left'\n",
    ")\n",
    "df_combinado_para_lstm_pre_feat['y_final_lstm_input'] = df_combinado_para_lstm_pre_feat['y_arima_feature'].fillna(df_combinado_para_lstm_pre_feat['y'])\n",
    "df_combinado_para_lstm_final = df_combinado_para_lstm_pre_feat[['ds', 'y_final_lstm_input']].rename(columns={'y_final_lstm_input': 'y'})\n",
    "\n",
    "df_combinado_para_lstm_final['dia_da_semana'] = df_combinado_para_lstm_final['ds'].dt.dayofweek\n",
    "df_combinado_para_lstm_final['mes_sin'] = np.sin(2 * np.pi * df_combinado_para_lstm_final['ds'].dt.month / 12)\n",
    "df_combinado_para_lstm_final['mes_cos'] = np.cos(2 * np.pi * df_combinado_para_lstm_final['ds'].dt.month / 12)\n",
    "df_combinado_para_lstm_final['dia_do_ano_sin'] = np.sin(2 * np.pi * df_combinado_para_lstm_final['ds'].dt.dayofyear / 365.25)\n",
    "df_combinado_para_lstm_final['dia_do_ano_cos'] = np.cos(2 * np.pi * df_combinado_para_lstm_final['ds'].dt.dayofyear / 365.25)\n",
    "\n",
    "features_lstm_cols = ['y', 'dia_da_semana', 'mes_sin', 'mes_cos', 'dia_do_ano_sin', 'dia_do_ano_cos']\n",
    "df_para_scaler_lstm = df_combinado_para_lstm_final[features_lstm_cols].copy()\n",
    "df_para_scaler_lstm.dropna(inplace=True) \n",
    "if df_para_scaler_lstm.empty: raise ValueError(\"DataFrame para scaler LSTM vazio.\")\n",
    "print(f\"Dados combinados com features sazonais para LSTM. Formato: {df_para_scaler_lstm.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 7: Normalização, Criação de Sequências e Treinamento do LSTM Híbrido\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Treinamento do Modelo LSTM Híbrido (10 anos com Features Sazonais) ---\")\n",
    "scaler_lstm_hibrido_10a_tuned = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data_hibrido_lstm_10a_tuned = scaler_lstm_hibrido_10a_tuned.fit_transform(df_para_scaler_lstm) \n",
    "scaler_lstm_path_10a_tuned = os.path.join(output_directory, 'scaler.pkl')\n",
    "joblib.dump(scaler_lstm_hibrido_10a_tuned, scaler_lstm_path_10a_tuned)\n",
    "print(f\">>> Scaler LSTM (Híbrido com Features, 10 anos) salvo como '{scaler_lstm_path_10a_tuned}' <<<\")\n",
    "\n",
    "seq_length_lstm_10a_tuned = 90 \n",
    "num_features_lstm = scaled_data_hibrido_lstm_10a_tuned.shape[1]\n",
    "print(f\"LSTM usará seq_length={seq_length_lstm_10a_tuned} e num_features={num_features_lstm}\")\n",
    "\n",
    "def create_sequences_multivariate_notebook(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    if len(data) <= seq_length: return np.array(xs), np.array(ys)\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:(i + seq_length), :]) \n",
    "        ys.append(data[i + seq_length, 0])    \n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X_hibrido_lstm_10a_tuned, y_hibrido_lstm_10a_tuned = create_sequences_multivariate_notebook(\n",
    "    scaled_data_hibrido_lstm_10a_tuned, seq_length_lstm_10a_tuned)\n",
    "if X_hibrido_lstm_10a_tuned.shape[0] == 0: raise ValueError(\"Nenhuma sequência LSTM multivariada criada.\")\n",
    "\n",
    "tam_validacao_lstm_10a = int(len(X_hibrido_lstm_10a_tuned) * 0.2) \n",
    "if tam_validacao_lstm_10a < 1 and len(X_hibrido_lstm_10a_tuned) > 1: tam_validacao_lstm_10a = 1\n",
    "elif len(X_hibrido_lstm_10a_tuned) <=1 : tam_validacao_lstm_10a = 0\n",
    "if len(X_hibrido_lstm_10a_tuned) - tam_validacao_lstm_10a <= 0 and len(X_hibrido_lstm_10a_tuned) > 0 :\n",
    "    tam_validacao_lstm_10a = 0 \n",
    "    print(\"AVISO: Poucos dados para validação LSTM, treinando com todos os dados de sequência.\")\n",
    "\n",
    "X_train_lstm_10a_tuned, X_val_lstm_10a_tuned = X_hibrido_lstm_10a_tuned[:-tam_validacao_lstm_10a] if tam_validacao_lstm_10a > 0 else X_hibrido_lstm_10a_tuned, \\\n",
    "                                             X_hibrido_lstm_10a_tuned[-tam_validacao_lstm_10a:] if tam_validacao_lstm_10a > 0 else np.array([])\n",
    "y_train_lstm_10a_tuned, y_val_lstm_10a_tuned = y_hibrido_lstm_10a_tuned[:-tam_validacao_lstm_10a] if tam_validacao_lstm_10a > 0 else y_hibrido_lstm_10a_tuned, \\\n",
    "                                             y_hibrido_lstm_10a_tuned[-tam_validacao_lstm_10a:] if tam_validacao_lstm_10a > 0 else np.array([])\n",
    "print(f\"Formato de X_train_lstm_tuned (multivariado): {X_train_lstm_10a_tuned.shape}\")\n",
    "if X_train_lstm_10a_tuned.shape[0] == 0: raise ValueError(\"X_train_lstm_10a_tuned está vazio.\")\n",
    "\n",
    "model_lstm_hibrido_10a_tuned = Sequential()\n",
    "model_lstm_hibrido_10a_tuned.add(LSTM(units=128, return_sequences=True, input_shape=(seq_length_lstm_10a_tuned, num_features_lstm)))\n",
    "model_lstm_hibrido_10a_tuned.add(Dropout(0.3))\n",
    "model_lstm_hibrido_10a_tuned.add(LSTM(units=128, return_sequences=False)) \n",
    "model_lstm_hibrido_10a_tuned.add(Dropout(0.3))\n",
    "model_lstm_hibrido_10a_tuned.add(Dense(64, activation='relu')) \n",
    "model_lstm_hibrido_10a_tuned.add(Dense(1))\n",
    "optimizer_10a_tuned = Adam(learning_rate=0.0005) \n",
    "model_lstm_hibrido_10a_tuned.compile(optimizer=optimizer_10a_tuned, loss='mean_squared_error')\n",
    "\n",
    "print(\"\\nIniciando treinamento do modelo LSTM híbrido com features sazonais (10 anos)...\")\n",
    "epochs_10a_tuned = 200 \n",
    "batch_size_10a_tuned = 80 \n",
    "early_stopping_10a = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "validation_data_lstm_10a = (X_val_lstm_10a_tuned, y_val_lstm_10a_tuned) if X_val_lstm_10a_tuned.shape[0] > 0 else None\n",
    "history_lstm_10a_tuned = model_lstm_hibrido_10a_tuned.fit(\n",
    "    X_train_lstm_10a_tuned, y_train_lstm_10a_tuned, epochs=epochs_10a_tuned, batch_size=batch_size_10a_tuned, \n",
    "    validation_data=validation_data_lstm_10a, callbacks=[early_stopping_10a] if validation_data_lstm_10a else [], verbose=1)\n",
    "print(\"Treinamento LSTM (10 anos com features) concluído.\")\n",
    "\n",
    "model_lstm_h5_path_10a_tuned = os.path.join(output_directory, 'lstm_model.h5')\n",
    "model_lstm_hibrido_10a_tuned.save(model_lstm_h5_path_10a_tuned)\n",
    "print(f\">>> Modelo LSTM híbrido (10 anos com features) salvo como '{model_lstm_h5_path_10a_tuned}' <<<\")\n",
    "\n",
    "if validation_data_lstm_10a and 'val_loss' in history_lstm_10a_tuned.history:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history_lstm_10a_tuned.history['loss'], label='Perda de Treino')\n",
    "    if 'val_loss' in history_lstm_10a_tuned.history:\n",
    "        plt.plot(history_lstm_10a_tuned.history['val_loss'], label='Perda de Validação')\n",
    "    plt.title('Perda do Modelo LSTM Ajustado (10 anos com Features)')\n",
    "    plt.xlabel('Época'); plt.ylabel('Perda'); plt.legend(); plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# CÉLULA 8: Avaliação (Exemplo) e Salvamento de df_erros.csv\n",
    "# ==============================================================================\n",
    "calculos_erro_list_notebook = [] \n",
    "if validation_data_lstm_10a and X_val_lstm_10a_tuned.shape[0] > 0:\n",
    "    pred_val_lstm_scaled_10a = model_lstm_hibrido_10a_tuned.predict(X_val_lstm_10a_tuned)\n",
    "    dummy_array_for_inverse = np.zeros((len(pred_val_lstm_scaled_10a), num_features_lstm))\n",
    "    dummy_array_for_inverse[:, 0] = pred_val_lstm_scaled_10a.flatten()\n",
    "    pred_val_lstm_original_scale_10a = scaler_lstm_hibrido_10a_tuned.inverse_transform(dummy_array_for_inverse)[:, 0]\n",
    "    dummy_array_for_inverse_y_true = np.zeros((len(y_val_lstm_10a_tuned), num_features_lstm))\n",
    "    dummy_array_for_inverse_y_true[:, 0] = y_val_lstm_10a_tuned.flatten()\n",
    "    y_val_original_scale_10a = scaler_lstm_hibrido_10a_tuned.inverse_transform(dummy_array_for_inverse_y_true)[:, 0]\n",
    "    print(\"\\nMétricas para LSTM Híbrido (10 anos com Features) no conjunto de validação:\")\n",
    "    print(calcula_erro_notebook(pred_val_lstm_original_scale_10a, y_val_original_scale_10a, \"LSTM_Hibrido_ feats_10Anos_Val\"))\n",
    "\n",
    "df_erros_path_notebook = os.path.join(output_directory, 'df_erros.csv')\n",
    "if calculos_erro_list_notebook:\n",
    "    df_erros_final_notebook = pd.DataFrame(calculos_erro_list_notebook)\n",
    "    df_erros_final_notebook.to_csv(df_erros_path_notebook, index=False)\n",
    "    print(f\">>> Métricas de erro salvas como '{df_erros_path_notebook}' <<<\")\n",
    "    print(\"\\nDataFrame de Erros (do Notebook):\\n\", df_erros_final_notebook)\n",
    "else:\n",
    "    print(f\"AVISO: 'calculos_erro_list_notebook' não populada. '{df_erros_path_notebook}' não foi criado.\")\n",
    "\n",
    "print(\"\\n--- Processo de Geração de Artefatos (10 anos, ARIMAX e LSTM com features) Concluído ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# NOVA SEÇÃO: Avaliação do Modelo AutoARIMAX (StatsForecast)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Avaliando Modelo AutoARIMAX (StatsForecast) no conjunto de validação ---\")\n",
    "\n",
    "# 1. Definir conjunto de treino e validação para ARIMAX\n",
    "# (Assumindo que df_fit_arimax_with_exog contém 'ds', 'y' (transformado), 'unique_id' e features exógenas)\n",
    "tam_validacao_arimax = int(len(df_fit_arimax_with_exog) * 0.2) # Exemplo: 20% para validação\n",
    "if tam_validacao_arimax < 1 and len(df_fit_arimax_with_exog) > 1:\n",
    "    tam_validacao_arimax = 1\n",
    "elif len(df_fit_arimax_with_exog) <= 1:\n",
    "    tam_validacao_arimax = 0\n",
    "\n",
    "df_treino_arimax = df_fit_arimax_with_exog[:-tam_validacao_arimax] if tam_validacao_arimax > 0 else df_fit_arimax_with_exog\n",
    "df_validacao_arimax_exog = df_fit_arimax_with_exog[-tam_validacao_arimax:].copy() if tam_validacao_arimax > 0 else pd.DataFrame()\n",
    "\n",
    "# Para obter os valores reais 'y' na escala original para comparação\n",
    "# Precisamos dos dados ANTES da transformação 'y_diff_log' mas DEPOIS do preenchimento de NaNs\n",
    "# df_transformed_10a_for_arimax tem 'ds', 'y_diff_log', 'y_ma_log'\n",
    "# df_normalized_hist_10a_for_lstm tem 'ds', 'y' (original após preenchimento e antes do log/diff)\n",
    "\n",
    "# Alinhar df_normalized_hist_10a_for_lstm (que tem o 'y' original) com o df_validacao_arimax_exog\n",
    "df_reais_val_arimax_temp = pipeline_arima_transform_nb.named_steps['filler_nan_values_arima'].transform(\n",
    "    pipeline_arima_transform_nb.named_steps['data_prepator_arima'].transform(df_brent_10anos_nb.copy())\n",
    ")\n",
    "df_reais_val_arimax_temp['ds'] = pd.to_datetime(df_reais_val_arimax_temp['ds'])\n",
    "\n",
    "if not df_validacao_arimax_exog.empty:\n",
    "    # Retreinar o modelo ARIMAX apenas com dados de treino se for fazer validação out-of-sample\n",
    "    model_sf_arimax_eval = StatsForecast(\n",
    "        models=[AutoARIMA(season_length=ARIMAX_SEASON_LENGTH)],\n",
    "        freq='D',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(\"Reajustando AutoARIMAX com dados de treino para avaliação...\")\n",
    "    model_sf_arimax_eval.fit(df_treino_arimax) # Treina com o conjunto de treino\n",
    "    print(\"AutoARIMAX reajustado.\")\n",
    "\n",
    "    # 2. Fazer previsões no conjunto de validação ARIMAX\n",
    "    h_validacao_arimax = len(df_validacao_arimax_exog)\n",
    "    # X_df para predict precisa de 'unique_id', 'ds' e as colunas exógenas do conjunto de validação\n",
    "    X_df_validacao_arimax = df_validacao_arimax_exog[['unique_id', 'ds'] + X_exog_arimax_unscaled_cols]\n",
    "\n",
    "    pred_validacao_arimax_transformed = model_sf_arimax_eval.predict(\n",
    "        h=h_validacao_arimax,\n",
    "        X_df=X_df_validacao_arimax\n",
    "    )\n",
    "\n",
    "    # 3. Reverter as transformações\n",
    "    # Precisamos do 'y_ma_log' correspondente ao período de validação\n",
    "    ma_log_validacao_arimax = df_transformed_10a_for_arimax.set_index('ds').loc[df_validacao_arimax_exog['ds']]['y_ma_log'].values\n",
    "\n",
    "    pred_col_arimax_eval = 'AutoARIMA' # ou a coluna correta de previsão\n",
    "    if pred_col_arimax_eval not in pred_validacao_arimax_transformed.columns and not pred_validacao_arimax_transformed.empty:\n",
    "        potential_cols = [col for col in pred_validacao_arimax_transformed.columns if col not in ['ds', 'unique_id']]\n",
    "        if potential_cols: pred_col_arimax_eval = potential_cols[0]\n",
    "        else: raise ValueError(\"Coluna de previsão não encontrada na validação ARIMAX\")\n",
    "\n",
    "\n",
    "    if len(ma_log_validacao_arimax) == len(pred_validacao_arimax_transformed[pred_col_arimax_eval]):\n",
    "        pred_validacao_arimax_original_scale = np.exp(\n",
    "            pred_validacao_arimax_transformed[pred_col_arimax_eval].values + ma_log_validacao_arimax\n",
    "        )\n",
    "\n",
    "        # Obter valores reais para o período de validação\n",
    "        y_reais_validacao_arimax_df = df_reais_val_arimax_temp.merge(\n",
    "            df_validacao_arimax_exog[['ds']], on='ds', how='inner'\n",
    "        )\n",
    "        y_reais_validacao_arimax = y_reais_validacao_arimax_df['y'].values\n",
    "\n",
    "\n",
    "        # 4. Calcular métricas de erro\n",
    "        if len(pred_validacao_arimax_original_scale) == len(y_reais_validacao_arimax):\n",
    "            print(\"\\nMétricas para AutoARIMAX (StatsForecast com Features) no conjunto de validação:\")\n",
    "            metricas_arimax = calcula_erro_notebook(\n",
    "                pred_validacao_arimax_original_scale,\n",
    "                y_reais_validacao_arimax,\n",
    "                \"ARIMAX_SF_feats_10Anos_Val\"\n",
    "            )\n",
    "            print(metricas_arimax)\n",
    "        else:\n",
    "            print(\"AVISO ARIMAX: Comprimento das previsões e reais de validação não coincide.\")\n",
    "            print(f\"Len preds: {len(pred_validacao_arimax_original_scale)}, Len reais: {len(y_reais_validacao_arimax)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"AVISO ARIMAX: Comprimento de ma_log_validacao e previsões não coincide.\")\n",
    "        print(f\"Len ma_log: {len(ma_log_validacao_arimax)}, Len preds: {len(pred_validacao_arimax_transformed[pred_col_arimax_eval])}\")\n",
    "else:\n",
    "    print(\"AVISO: Conjunto de validação ARIMAX está vazio. Nenhuma métrica ARIMAX será calculada.\")\n",
    "\n",
    "# (A CÉLULA 8 original viria depois, garantindo que calculos_erro_list_notebook agora tenha as métricas do ARIMAX também)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
